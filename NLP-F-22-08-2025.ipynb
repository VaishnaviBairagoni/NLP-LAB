{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ12KJsWd+dShlZKl0CIMw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VaishnaviBairagoni/NLP-LAB/blob/main/NLP-F-22-08-2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sJZH1dH5_lY",
        "outputId": "2a690f46-81e2-413d-83a3-9653940241ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (1367, 17)\n",
            "\n",
            "Columns: Index(['text_content', 'content_type', 'word_count', 'character_count',\n",
            "       'sentence_count', 'lexical_diversity', 'avg_sentence_length',\n",
            "       'avg_word_length', 'punctuation_ratio', 'flesch_reading_ease',\n",
            "       'gunning_fog_index', 'grammar_errors', 'passive_voice_ratio',\n",
            "       'predictability_score', 'burstiness', 'sentiment_score', 'label'],\n",
            "      dtype='object')\n",
            "\n",
            "First 5 text_content entries:\n",
            " 0    Score each cause. Quality throughout beautiful...\n",
            "1    Board its rock. Job worker break tonight coupl...\n",
            "2    Way debate decision produce. Dream necessary c...\n",
            "3    Story turn because such during open model. Tha...\n",
            "4    Place specific as simply leader fall analysis....\n",
            "Name: text_content, dtype: object\n",
            "\n",
            "Null values after cleaning: 0\n"
          ]
        }
      ],
      "source": [
        "#Task 1:Dataset Loading and cleaning\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "# Load the dataset (Assuming the file is named 'train.csv')\n",
        "df = pd.read_csv('/ai_human_content_detection_dataset.csv')\n",
        "\n",
        "# Inspect the structure\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nColumns:\", df.columns)\n",
        "\n",
        "# Display first 5 entries of ''\n",
        "print(\"\\nFirst 5 text_content entries:\\n\", df['text_content'].head())\n",
        "\n",
        "# Clean null values\n",
        "df = df.dropna(subset=['text_content'])\n",
        "print(\"\\nNull values after cleaning:\", df['text_content'].isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task-2:POS tagging with spaCy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Take first 5 entries from 'description_x'\n",
        "sentences = df['description_x'].head(5).tolist()\n",
        "\n",
        "for idx, sentence in enumerate(sentences, 1):\n",
        "    print(f\"\\nSentence {idx}: {sentence}\")\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
        "    verbs = [token.text for token in doc if token.pos_ == \"VERB\"]\n",
        "    adjectives = [token.text for token in doc if token.pos_ == \"ADJ\"]\n",
        "\n",
        "    print(\"Nouns:\", nouns)\n",
        "    print(\"Verbs:\", verbs)\n",
        "    print(\"Adjectives:\", adjectives)\n",
        "\n",
        "# Q2: Regex Cleaning - Remove phone, email, URLs, special chars\n",
        "texts = [\n",
        "    \"My phone number is 1234567890 and my email is test@domain.com\",\n",
        "    \"Visit https://example.com for more info!!!\",\n",
        "    \"HELLO!!! This is SOOOOO exciting :))\",\n",
        "    \"Contact us at info@company.org or call +91 98765-43210\",\n",
        "    \"Python's regex is very useful!!!  #Coding #Fun\"\n",
        "]\n",
        "\n",
        "cleaned_texts = []\n",
        "\n",
        "for text in texts:\n",
        "    # Remove phone numbers\n",
        "    text = re.sub(r'\\+?\\d[\\d -]{8,}\\d', '', text)\n",
        "\n",
        "    # Remove emails\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
        "\n",
        "    # Remove special characters (except spaces and letters)\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    cleaned_texts.append(text)\n",
        "\n",
        "print(\"\\nCleaned Texts:\")\n",
        "for ct in cleaned_texts:\n",
        "    print(ct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8kPXrbQ_a4-",
        "outputId": "19866e69-6e0c-4780-ce3a-90ebb3d765bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "Sentence 1: semtech corp\n",
            "Nouns: []\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "\n",
            "Sentence 2: vanguard mid cap index\n",
            "Nouns: ['index']\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "\n",
            "Sentence 3: spdr gold trust gold shares\n",
            "Nouns: ['spdr', 'gold', 'trust', 'gold', 'shares']\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "\n",
            "Sentence 4: vanguard total bond index adm\n",
            "Nouns: ['index']\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "\n",
            "Sentence 5: oakmark international fund class i\n",
            "Nouns: ['fund', 'class']\n",
            "Verbs: []\n",
            "Adjectives: ['international']\n",
            "\n",
            "Cleaned Texts:\n",
            "My phone number is and my email is\n",
            "Visit for more info\n",
            "HELLO This is SOOOOO exciting\n",
            "Contact us at or call\n",
            "Pythons regex is very useful Coding Fun\n"
          ]
        }
      ]
    }
  ]
}